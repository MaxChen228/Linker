#!/usr/bin/env python3
"""
ä¿®å¾© knowledge.json ä¸­çš„é‡è¤‡æ•¸æ“šå•é¡Œ
- ä¿®å¾©é‡è¤‡çš„ ID
- ç§»é™¤å®Œå…¨ç›¸åŒçš„çŸ¥è­˜é»
- ä¿ç•™æœ€æ—©å‰µå»ºçš„ç‰ˆæœ¬
"""

import json
import os
import shutil
import sys
from datetime import datetime
from typing import Any


def load_knowledge_data(file_path: str) -> dict[str, Any]:
    """è¼‰å…¥çŸ¥è­˜é»æ•¸æ“š"""
    if not os.path.exists(file_path):
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        sys.exit(1)

    with open(file_path, encoding='utf-8') as f:
        return json.load(f)


def save_knowledge_data(data: dict[str, Any], file_path: str) -> None:
    """ä¿å­˜çŸ¥è­˜é»æ•¸æ“š"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def backup_file(file_path: str) -> str:
    """å‚™ä»½åŸå§‹æª”æ¡ˆ"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = f"{file_path}.backup_{timestamp}"
    shutil.copy2(file_path, backup_path)
    print(f"âœ… å·²å‚™ä»½è‡³: {backup_path}")
    return backup_path


def fix_duplicate_ids(points: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """ä¿®å¾©é‡è¤‡çš„ ID"""
    seen_ids = set()
    max_id = 0
    fixed_points = []

    for point in points:
        current_id = point.get('id', 0)

        # è¿½è¹¤æœ€å¤§ ID
        if current_id > max_id:
            max_id = current_id

        # å¦‚æœ ID é‡è¤‡ï¼Œåˆ†é…æ–° ID
        if current_id in seen_ids:
            max_id += 1
            point['id'] = max_id
            print(f"  ä¿®å¾©é‡è¤‡ ID: {current_id} â†’ {max_id}")

        seen_ids.add(point['id'])
        fixed_points.append(point)

    return fixed_points


def remove_duplicate_content(points: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """ç§»é™¤å…§å®¹å®Œå…¨ç›¸åŒçš„çŸ¥è­˜é»ï¼Œä¿ç•™æœ€æ—©çš„"""
    unique_points = {}
    duplicates_removed = 0

    for point in points:
        # ç”Ÿæˆå…§å®¹éµï¼ˆç”¨æ–¼è­˜åˆ¥é‡è¤‡ï¼‰
        content_key = (
            point.get('key_point', ''),
            point.get('original_phrase', ''),
            point.get('correction', '')
        )

        if content_key in unique_points:
            # æ¯”è¼ƒå‰µå»ºæ™‚é–“ï¼Œä¿ç•™è¼ƒæ—©çš„
            existing = unique_points[content_key]
            existing_time = datetime.fromisoformat(existing.get('created_at', '2099-12-31'))
            current_time = datetime.fromisoformat(point.get('created_at', '2099-12-31'))

            if current_time < existing_time:
                # ç•¶å‰çš„æ›´æ—©ï¼Œæ›¿æ›
                print(f"  æ›¿æ›é‡è¤‡: ID {existing['id']} â†’ ID {point['id']} (è¼ƒæ—©)")
                unique_points[content_key] = point
            else:
                print(f"  ç§»é™¤é‡è¤‡: ID {point['id']} ('{content_key[0][:30]}...')")

            duplicates_removed += 1
        else:
            unique_points[content_key] = point

    return list(unique_points.values()), duplicates_removed


def analyze_data_quality(points: list[dict[str, Any]]) -> None:
    """åˆ†ææ•¸æ“šè³ªé‡"""
    print("\nğŸ“Š æ•¸æ“šè³ªé‡åˆ†æ:")
    print(f"  ç¸½è¨˜éŒ„æ•¸: {len(points)}")

    # æª¢æŸ¥ ID å”¯ä¸€æ€§
    ids = [p.get('id') for p in points]
    unique_ids = set(ids)
    print(f"  å”¯ä¸€ ID æ•¸: {len(unique_ids)}")

    # æª¢æŸ¥å…§å®¹å”¯ä¸€æ€§
    content_keys = set()
    for p in points:
        key = (p.get('key_point', ''), p.get('original_phrase', ''), p.get('correction', ''))
        content_keys.add(key)
    print(f"  å”¯ä¸€å…§å®¹æ•¸: {len(content_keys)}")

    # æª¢æŸ¥é¡åˆ¥åˆ†å¸ƒ
    categories = {}
    for p in points:
        if not p.get('is_deleted', False):
            cat = p.get('category', 'unknown')
            categories[cat] = categories.get(cat, 0) + 1

    print("\n  é¡åˆ¥åˆ†å¸ƒ:")
    for cat, count in sorted(categories.items()):
        valid = 'âœ“' if cat in ['systematic', 'isolated', 'enhancement', 'other'] else 'âœ—'
        print(f"    {cat}: {count} {valid}")

    # æª¢æŸ¥ç„¡æ•ˆæ•¸æ“š
    invalid_mastery = sum(1 for p in points
                          if p.get('mastery_level', 0) < 0 or p.get('mastery_level', 0) > 1)
    negative_counts = sum(1 for p in points
                          if p.get('mistake_count', 0) < 0 or p.get('correct_count', 0) < 0)

    print("\n  æ•¸æ“šå•é¡Œ:")
    print(f"    ç„¡æ•ˆæŒæ¡åº¦: {invalid_mastery}")
    print(f"    è² æ•¸è¨ˆæ•¸: {negative_counts}")


def main():
    """ä¸»ç¨‹åº"""
    file_path = 'data/knowledge.json'

    print("ğŸ”§ çŸ¥è­˜é»æ•¸æ“šä¿®å¾©å·¥å…·")
    print("=" * 50)

    # è¼‰å…¥æ•¸æ“š
    print("\n1ï¸âƒ£ è¼‰å…¥æ•¸æ“š...")
    data = load_knowledge_data(file_path)
    points = data.get('data', data.get('knowledge_points', []))
    original_count = len(points)

    print(f"  è¼‰å…¥ {original_count} æ¢è¨˜éŒ„")

    # åˆ†æåŸå§‹æ•¸æ“š
    print("\n2ï¸âƒ£ åˆ†æåŸå§‹æ•¸æ“š...")
    analyze_data_quality(points)

    # è‡ªå‹•ç¹¼çºŒï¼ˆéäº’å‹•æ¨¡å¼ï¼‰
    print("\nè‡ªå‹•æ¨¡å¼ï¼šç¹¼çºŒä¿®å¾©...")

    # å‚™ä»½åŸå§‹æª”æ¡ˆ
    print("\n3ï¸âƒ£ å‚™ä»½åŸå§‹æª”æ¡ˆ...")
    backup_path = backup_file(file_path)

    # ä¿®å¾©é‡è¤‡ ID
    print("\n4ï¸âƒ£ ä¿®å¾©é‡è¤‡ ID...")
    points = fix_duplicate_ids(points)

    # ç§»é™¤é‡è¤‡å…§å®¹
    print("\n5ï¸âƒ£ ç§»é™¤é‡è¤‡å…§å®¹...")
    points, duplicates_removed = remove_duplicate_content(points)

    # é‡æ–°æ’åº ID
    print("\n6ï¸âƒ£ é‡æ–°æ’åº ID...")
    points.sort(key=lambda x: x.get('created_at', ''))
    for i, point in enumerate(points, 1):
        if point['id'] != i:
            print(f"  é‡æ–°ç·¨è™Ÿ: ID {point['id']} â†’ {i}")
            point['id'] = i

    # æ›´æ–°æ•¸æ“šçµæ§‹
    data['data'] = points
    data['last_updated'] = datetime.now().isoformat()

    # ä¿å­˜ä¿®å¾©å¾Œçš„æ•¸æ“š
    print("\n7ï¸âƒ£ ä¿å­˜ä¿®å¾©å¾Œçš„æ•¸æ“š...")
    save_knowledge_data(data, file_path)

    # æœ€çµ‚åˆ†æ
    print("\n8ï¸âƒ£ ä¿®å¾©å¾Œçš„æ•¸æ“šåˆ†æ:")
    analyze_data_quality(points)

    # ç¸½çµ
    print("\n" + "=" * 50)
    print("âœ… ä¿®å¾©å®Œæˆ!")
    print(f"  åŸå§‹è¨˜éŒ„æ•¸: {original_count}")
    print(f"  ä¿®å¾©å¾Œè¨˜éŒ„æ•¸: {len(points)}")
    print(f"  ç§»é™¤é‡è¤‡: {original_count - len(points)}")
    print(f"  å‚™ä»½æª”æ¡ˆ: {backup_path}")

    # é©—è­‰å»ºè­°
    print("\nğŸ’¡ å»ºè­°å¾ŒçºŒæ“ä½œ:")
    print("  1. æª¢æŸ¥ä¿®å¾©å¾Œçš„æ•¸æ“š: cat data/knowledge.json | python -m json.tool | head -50")
    print("  2. å¦‚æœæœ‰å•é¡Œï¼Œæ¢å¾©å‚™ä»½: cp " + backup_path + " data/knowledge.json")
    print("  3. æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼æ˜¯å¦æ­£å¸¸é‹è¡Œ")


if __name__ == "__main__":
    main()
